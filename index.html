<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="DyCodeEval, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DyCodeEval: Dyanmic Benchmarking of Reasoning Capabilities in Code Large Language Models under Data Contamination</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DyCodeEval: Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models under Data Contamination</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://siminchen.site">Simin Chen</a>,</span>
            <span class="author-block">
              <a href="">Pranav Pusarla</a>,</span>
            <span class="author-block">
              <a href="https://www.rayb.info">Baishakhi Ray</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Columbia University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.07974" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/LiveCodeBench/LiveCodeBench"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Introduction -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <span class="dnerf">DyCodeEval</span> is a novel dynamic benchmarking suite that employs multiple agents 
          to generate a set of diverse semantically equivalent problems in order to provide transparent contamination-free
          evaluation on code LLMs. Below is an example of a problem that was generated by <span class="dnerf">DyCodeEval</span>
          from the seed programming problem.
        </div>
        <div class="columns is-centered">
          <!-- center the image -->
          <img src="./images/dycodeeval_example.png" alt="Teaser" class="teaser-image center" width="60%" />
        </div>
      </div>
    </div>
    <!--/ Introduction -->
  </div>
</section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Design Overview -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Design Overview</h2>
          <div class="columns is-centered">
            <!-- center the image -->
            <img src="./images/design_overview.png" alt="Teaser" class="teaser-image center" />
          </div>
          <div class="content has-text-justified">
            <span class="dnerf">DyCodeEval</span> uses four different agents to generate a diverse problem set: 
            Scenario Proposer, Context Generator, Prompt Rewriter, Validator. The Scenario Proposer
            selects scenarios from a predefined pool and uses them to iteratively generate more scenarios
            through LLM prompting. The Context Generator selects a scenario at random and assigns
            contextual information to each input variable of the problem based on the chosen scenario. The
            Prompt Rewriter uses the contextual information and scenario to rewrite the original programming
            problem. The Validator then determines whether the original and newly generated problem are consistent
            in core concept and solution.
          </div>
        </div>
      </div>
      <!--/ Design Overview -->
    </div>
  </section>
  
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Contaminated Model Evaluation -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Contaminated Model Evaluation</h2>
          <div class="columns is-centered">
            <!-- center the image -->
            <img src="./images/contaminated_eval.png" alt="Teaser" class="teaser-image center" width="80%"/>
          </div>
          <div class="content has-text-justified">
            To determine the extent of model contamination and the validity of <span class="dnerf">DyCodeEval</span>, we ran
            experiments with three different models where we simulated model contamination by finetuning the model with increasing
            percentages of the dataset. From the top row, we can see that all the models that are finetuned with a specific leaked
            dataset increase in accuracy rapidly when evaluated on that dataset. However, in the bottom row, we see that even though
            the dataset is leaked, the models maintain the same accuracy due to <span class="dnerf">DyCodeEval</span>: 
            our dynamic benchmarking method.
          </div>
        </div>
      </div>
      <!--/ Contaminated Model Evaluation -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- On-the-Wild Benchmarking -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">On-the-Wild Benchmarking</h2>
          <div class="columns is-centered">
            <!-- center the image -->
            <img src="./images/wild_benchmarking.png" alt="Teaser" class="teaser-image center" width="90%"/>
          </div>
          <div class="content has-text-justified">
            We further evaluate <span class="dnerf">DyCodeEval</span> on 12 more on-the-wild code LLMs. We observe that for 
            both datasets, the overfitted model appears as an outlier while the original models <span class="pass1">Pass@1</span> 
            scores maintain a linear relationship.
          </div>
        </div>
      </div>
      <!--/ On-the-Wild Benchmarking -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Stability Assessment -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Stability Assessment</h2>
          <div class="columns is-centered">
            <!-- center the image -->
            <img src="./images/model_stability.png" alt="Teaser" class="teaser-image center" width="70%"/>
          </div>
          <div class="content has-text-justified">
            Since <span class="dnerf">DyCodeEval</span> generates a unique benchmarking dataset each time, we run a 
            stability assessment to determine if consistency is maintained. We find that the variance in benchmarking
            scores is minimal to the mean when <span class="pass1">Pass@1</span> is measured after being run 10 different
            times demonstrating <span class="dnerf">DyCodeEval</span>'s stability.
          </div>
        </div>
      </div>
      <!--/ Stability Assessment -->
    </div>
  </section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The source code for this website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">here</a>!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>